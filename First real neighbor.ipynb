{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code mostly is same as \"First neighbor\" but here I search not one nearest neighbor but all of them with equal distance and then search nearest across real size of them.\n",
    "\n",
    "Also here will be comparing one part from train with rest four parts (validation) due to calculate the metric (in \"First neighbor\" test was compared with train).\n",
    "\n",
    "So the result will save as sorted list of tuples like (dice coefficient, some image from first part, real nearest neighbor from other parts). Therefore you can look at the first few records in {result.csv} and find out the worst result and the pictures which gave it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and constants\n",
    "\n",
    "import numpy as np # importing numpy for work with matrices\n",
    "import csv # importing csv to work with train_masks.csv\n",
    "from scipy.spatial import KDTree # importing KDTree for fast neighbor searching\n",
    "from time import gmtime, strftime # importing some stuff from time to check the speed for algorithm\n",
    "\n",
    "TIF = len(\".tif\")\n",
    "EPS = 0.001\n",
    "\n",
    "NUMBER_OF_PARTS = 5\n",
    "\n",
    "SORTED_LIST = \"input/sorted.csv\"\n",
    "ARCHIVE = \"input/new_train_data.npz\"\n",
    "REAL_ARCHIVE = \"input/train_data.npz\"\n",
    "RESULT = \"input/result.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metric function\n",
    "# x and y should be same-sized arrays of 0s and 1s\n",
    "\n",
    "def dice_coefficient(x, y):\n",
    "    if not(x.any() or y.any()):\n",
    "        return 1\n",
    "    return 2 * (x.astype(bool) * y.astype(bool)).sum() / (x.sum() + y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forming %NUMBER_OF_PARTS% proportional parts of arrays in new_train (small images)\n",
    "\n",
    "sort = []\n",
    "with open(SORTED_LIST) as sorted_list:\n",
    "    reader = csv.reader(sorted_list)\n",
    "    for row in reader:\n",
    "        if len(row) == 2:\n",
    "            sort.append(row[1])\n",
    "\n",
    "part = [i for i in range(NUMBER_OF_PARTS)]\n",
    "for i in range(NUMBER_OF_PARTS):\n",
    "    part[i] = sort[i::NUMBER_OF_PARTS]\n",
    "    \n",
    "del sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-22 14:11:26\n",
      "1127\n",
      "4508\n",
      "2016-07-22 14:11:26\n"
     ]
    }
   ],
   "source": [
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) # don't forget to add 3 hours\n",
    "\n",
    "part_to_test = 0\n",
    "\n",
    "test_names = part[part_to_test]\n",
    "train_names = []\n",
    "for i in range(NUMBER_OF_PARTS):\n",
    "    if i != part_to_test:\n",
    "        train_names += part[i]\n",
    "        \n",
    "del part_to_test\n",
    "\n",
    "print(len(test_names))\n",
    "print(len(train_names))\n",
    "        \n",
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) # don't forget to add 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-22 14:11:30\n",
      "2016-07-22 14:12:46\n"
     ]
    }
   ],
   "source": [
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) # don't forget to add 3 hours\n",
    "\n",
    "with np.load(ARCHIVE, mmap_mode='r') as data:\n",
    "    test_images = np.array([data[image_name].flatten() for image_name in test_names]).astype(int)\n",
    "    train_images = np.array([data[image_name].flatten() for image_name in train_names]).astype(int)\n",
    "        \n",
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) # don't forget to add 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-22 14:30:38\n",
      "2016-07-22 14:33:02\n"
     ]
    }
   ],
   "source": [
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) # don't forget to add 3 hours\n",
    "\n",
    "tree = KDTree(train_images, leafsize=200)\n",
    "        \n",
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) # don't forget to add 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-22 16:04:26\n",
      "2016-07-22 17:41:25\n"
     ]
    }
   ],
   "source": [
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) # don't forget to add 3 hours\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    \n",
    "    dist, ind = tree.query(test_images[i], k=1, p=2)\n",
    "    neighbors_indeces = tree.query_ball_point(test_images[i], dist + EPS)\n",
    "\n",
    "    with np.load(REAL_ARCHIVE, mmap_mode='r') as data:\n",
    "        real_example = data[test_names[i]].flatten()\n",
    "        real_neighbors = np.array([data[img].flatten() for img in np.array(train_names)[neighbors_indeces]]).astype(int)\n",
    "\n",
    "    real_tree = KDTree(real_neighbors, leafsize=10)\n",
    "    dist, ind = real_tree.query(real_example, k=1, p=2)\n",
    "    real_neighbor_name = train_names[neighbors_indeces[ind]]\n",
    "\n",
    "    with np.load(REAL_ARCHIVE, mmap_mode='r') as data:\n",
    "        example_mask = data[test_names[i][:-TIF] + \"_mask.tif\"]\n",
    "        neighbor_mask = data[real_neighbor_name[:-TIF] + \"_mask.tif\"]\n",
    "\n",
    "    result.append((dice_coefficient(example_mask, neighbor_mask), test_names[i], real_neighbor_name))\n",
    "    \n",
    "result.sort()\n",
    "    \n",
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) # don't forget to add 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(RESULT, \"w\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46927067909622322"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.array(result)\n",
    "np.average(result[:,0].astype(float))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
